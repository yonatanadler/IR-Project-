{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb869591-5e42-450f-b9c7-038295df1fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%cd -q /home/dataproc\n",
    "from inverted_index_gcp_new import InvertedIndex, MultiFileReader\n",
    "from bm25 import BM_25\n",
    "from backend import *\n",
    "from search_fronted import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30732241-6068-4b96-9d8e-cbfb93d1db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "     \n",
    "with open('all_new.json', 'rt') as f:\n",
    "  queries = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c4ef5-6a33-440d-ae30-7fa86c3ad63f",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066ec2cb-ff8c-4d32-bf1c-cdc4dc0269a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(true_list, predicted_list, k=40):\n",
    "    true_set = set(true_list)\n",
    "    predicted_subset = predicted_list[:k]\n",
    "    matches = [item for item in predicted_subset if item in true_set]\n",
    "    return round(len(matches) / len(true_list), 3)\n",
    "\n",
    "def precision_at_k(true_list, predicted_list, k=40):\n",
    "    true_set = set(true_list)\n",
    "    predicted_subset = predicted_list[:k]\n",
    "    matches = len([item for item in predicted_subset if item in true_set])\n",
    "    return round(matches / k, 3)\n",
    "\n",
    "def r_precision(true_list, predicted_list):\n",
    "    true_set = set(true_list)\n",
    "    predicted_subset = predicted_list[:len(true_list)]\n",
    "    matches = [item for item in predicted_subset if item in true_set]\n",
    "    return round(len(matches) / len(true_list), 3)\n",
    "\n",
    "def reciprocal_rank_at_k(true_list, predicted_list, k=40):\n",
    "    true_set = set(true_list)\n",
    "    predicted_subset = predicted_list[:k]\n",
    "    for i, item in enumerate(predicted_subset):\n",
    "        if item in true_set:\n",
    "            return round(1 / (i + 1), 3)\n",
    "    return 0.000\n",
    "\n",
    "def f_score(true_list,predicted_list,k=40):\n",
    "    \n",
    "    precision = precision_at_k(true_list,predicted_list,k)\n",
    "    recall = recall_at_k(true_list,predicted_list,k)\n",
    "    if precision == 0 and recall == 0:\n",
    "      return 0\n",
    "    else:\n",
    "      return round((2 * precision * recall) / (precision + recall), 3)\n",
    "\n",
    "def average_precision(true_list, predicted_list, k=40):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    precisions = []\n",
    "    for i,doc_id in enumerate(predicted_list):        \n",
    "        if doc_id in true_set:\n",
    "            prec = (len(precisions)+1) / (i+1)            \n",
    "            precisions.append(prec)\n",
    "    if len(precisions) == 0:\n",
    "        return 0.0\n",
    "    return round(sum(precisions)/len(precisions),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0bf1c-ce58-48be-92fe-286ead7d8818",
   "metadata": {},
   "source": [
    "Test all queries with MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367371a-996f-4efc-a1e3-f648e4e23f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [01:18<00:07,  2.45s/it]"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "map_avg = []\n",
    "sum_duration = 0\n",
    "pred_wids = {}\n",
    "map25 = True\n",
    "duration_35 = True\n",
    "for q, true_wids in tqdm(queries.items()):\n",
    "    duration, ap = None, None\n",
    "    t_start = time.time()\n",
    "    search_all_q = search(q) \n",
    "    duration = time.time() - t_start\n",
    "    pred = [i[0] for i in search_all_q]\n",
    "    pred_wids[q] = pred\n",
    "    if duration > 35: duration_35 = False\n",
    "    sum_duration += duration\n",
    "    ap = average_precision(true_wids, pred)\n",
    "    map_avg.append(ap)\n",
    "    result.append((q, duration, ap))\n",
    "    \n",
    "if builtins.sum(map_avg) / len(map_avg) < 0.25: map25 = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b47287-8b17-48ef-b1b6-21ef33dfcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duration for each query < 35s : \" + str(duration_35))\n",
    "print(\"MAP@40 > 0.25   : \" + str(map25))\n",
    "print(\"MAP@40: \" + str(builtins.sum(map_avg) / len(map_avg)))\n",
    "print(\"AVG Duration   : \" + str(sum_duration/len(queries)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82582e2-52e7-470d-bece-a05bde35212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(result, columns=['Query', 'duration', \"average precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658496a-076a-4c00-ad16-1ef12ee913e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_lst, precision_lst, f_score_lst, r_precision_lst, reciprocal_rank_lst, avg_precision_lst = [], [], [], [], [], []\n",
    "metrices = {'recall@k':recall_lst,\n",
    "            'precision@k':precision_lst,\n",
    "            'f_score@k': f_score_lst,\n",
    "            'r-precision': r_precision_lst,\n",
    "            'MRR@k':reciprocal_rank_lst,\n",
    "            'MAP@k':avg_precision_lst}\n",
    "\n",
    "for query, true in queries.items():  \n",
    "    predicted = pred_wids[query]\n",
    "    recall_lst.append(recall_at_k(true,predicted,k=40))\n",
    "    precision_lst.append(precision_at_k(true,predicted,k=40))\n",
    "    f_score_lst.append(f_score(true,predicted,k=40))\n",
    "    r_precision_lst.append(r_precision(true,predicted))\n",
    "    reciprocal_rank_lst.append(reciprocal_rank_at_k(true,predicted,k=40))\n",
    "    avg_precision_lst.append(average_precision(true,predicted,k=40))\n",
    "\n",
    "for name,values in metrices.items():\n",
    "        print(name,sum(values)/len(values))\n",
    "\n",
    "metrices_names = ['precision@k','recall@k','f_score@k','r-precision','MRR@k','MAP@k']\n",
    "for metric_name in metrices_names:\n",
    "    met = metrices\n",
    "    met_list = met[metric_name]\n",
    "    plt.xlabel(\"Queries\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(metric_name)\n",
    "    plt.plot([i+1 for i in range(len(met_list))], met_list)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a2a0d-1b6c-4df2-8dc0-3b4219070712",
   "metadata": {},
   "source": [
    "PAGE RANK RESEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148cd9e-8108-4740-a560-719ab6711e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = get_pr()\n",
    "sort_dic = sorted(list( pr.items()),key=lambda x: x[1])\n",
    "values = list(pr.values())\n",
    "num_of_pages =(len(values))\n",
    "pstdev=statistics.pstdev(values)\n",
    "variance = statistics.pvariance(values)\n",
    "median = statistics.median(values)\n",
    "Max_pr = max(pr.values())\n",
    "Min_pr = min(pr.values())\n",
    "\n",
    "print(f\"number of pages: {num_of_pages}\")\n",
    "print(f\"Max page rank is : {Max_pr} \")\n",
    "print(f\"Min page rank is : {Min_pr} \")\n",
    "print(f\"Median of page ranks is : {median}\")\n",
    "print(f\"pstdev of page ranks is : {pstdev}\")\n",
    "print(f\"variance of page ranks is : {variance}\")\n",
    "print(f\"average of page rank is : {sum(values)/len(values)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e727d-4bd0-46c3-b424-7d765d359d38",
   "metadata": {},
   "source": [
    "PAGE VIEW RESEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dfa2c5-ea52-4014-beee-b5a685e20c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = get_pv()\n",
    "sort_dic = sorted(list( pv.items()),key=lambda x: x[1])\n",
    "values = list(pr.values())\n",
    "num_of_pages =(len(values))\n",
    "pstdev=statistics.pstdev(values)\n",
    "variance = statistics.pvariance(values)\n",
    "median = statistics.median(values)\n",
    "Max_pr = max(pv.values())\n",
    "Min_pr = min(pv.values())\n",
    "\n",
    "print(f\"number of pages: {num_of_pages}\")\n",
    "print(f\"Max page rank is : {Max_pr} \")\n",
    "print(f\"Min page rank is : {Min_pr} \")\n",
    "print(f\"Median of page ranks is : {median}\\n\")\n",
    "print(f\"pstdev of page ranks is : {pstdev}\\n\")\n",
    "print(f\"variance of page ranks is : {variance}\\n\")\n",
    "print(f\"average of page rank is : {sum(values)/len(values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc28c1-f82c-4739-a834-081842d211af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01818b-3ecf-4262-83bc-4c05ffc6800d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
